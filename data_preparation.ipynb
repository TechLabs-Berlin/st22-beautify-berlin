{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE THE WORKSPACE\n",
    "\n",
    "#%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import matplotlib.pyplot as plts\n",
    "#from sklearn.model_selection import train_test_split\n",
    "# I think I do only need np and pd right here at this point. We will see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Treptow-Kopenick              79\n",
       "Neukolln                      72\n",
       "Friedrichshain-Kreuzberg      65\n",
       "Steglitz-Zehlendorf           64\n",
       "Spandau                       64\n",
       "Charlottenburg-Wilmersdorf    63\n",
       "Mitte                         61\n",
       "Lichtenberg                   60\n",
       "Reinickendorf                 60\n",
       "Marzahn-Hellersdorf           59\n",
       "Pankow                        54\n",
       "Tempelhof-Schoneberg          49\n",
       "Name: district, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ THE DATA\n",
    "# the data is synthetic. I generated it in order to have data to work with\n",
    "# it contains artworks created by the \"Beautify Berlin\" community inlcuding data about the type of artwork, the district it can be found in and further\n",
    "# \"Column1\" contained the index in the *.txt file and was dropped since it would have been redundant\n",
    "\n",
    "artworks = pd.read_table(\"beautified_boxes.txt\").drop(\"Column1\", axis=1)\n",
    "print(artworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treptow-Kopenick              79\n",
      "Neukolln                      72\n",
      "Friedrichshain-Kreuzberg      65\n",
      "Steglitz-Zehlendorf           64\n",
      "Spandau                       64\n",
      "Charlottenburg-Wilmersdorf    63\n",
      "Mitte                         61\n",
      "Lichtenberg                   60\n",
      "Reinickendorf                 60\n",
      "Marzahn-Hellersdorf           59\n",
      "Pankow                        54\n",
      "Tempelhof-Schoneberg          49\n",
      "Name: district, dtype: int64\n",
      "\n",
      "\n",
      "     Artwork-Id  type                  district  environment  countArtists  \\\n",
      "0      32048698     5          Treptow-Kopenick  main street             2   \n",
      "1      39800694     5          Treptow-Kopenick         park             3   \n",
      "2      80318972     4          Treptow-Kopenick  public spot             3   \n",
      "3      74478002     4          Treptow-Kopenick  main street             4   \n",
      "4      71449602     5       Steglitz-Zehlendorf  side street             3   \n",
      "..          ...   ...                       ...          ...           ...   \n",
      "745    68311402     5      Tempelhof-Schoneberg  side street             2   \n",
      "746    22390811     5                     Mitte         park             2   \n",
      "747    19230282     5  Friedrichshain-Kreuzberg         park             1   \n",
      "748    29644044     5          Treptow-Kopenick  side street             2   \n",
      "749    55964034     4                   Spandau  main street             1   \n",
      "\n",
      "     experience            replaced             content  userRating  approval  \n",
      "0    first time             nothing   animals or plants         4.0         1  \n",
      "1      beginner              poster           political         2.0         0  \n",
      "2      beginner   stickers and tags             scenery         4.0         0  \n",
      "3    first time     recent graffiti  cartoon or comical         4.0         0  \n",
      "4      beginner              poster  cartoon or comical         0.0         0  \n",
      "..          ...                 ...                 ...         ...       ...  \n",
      "745  first time  weathered graffiti           political         3.0         1  \n",
      "746    beginner  weathered graffiti  cartoon or comical         5.0         1  \n",
      "747    advanced  weathered graffiti              people         5.0         1  \n",
      "748    advanced   stickers and tags             scenery         3.0         1  \n",
      "749  first time              poster             scenery         0.0         0  \n",
      "\n",
      "[750 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# PROCESS THE DATA\n",
    "\n",
    "# some artworks have no user rating, thus the column \"userRating\" contains NaN in these cases\n",
    "# during labeling, a missing user rating was a disadvantage in the process of approval\n",
    "# thus, fill the missing values with the numerical value 0  \n",
    "\n",
    "artworks_processed = artworks.fillna(0)\n",
    "\n",
    "# currently, the categories are not numerical and not ordered\n",
    "# transform the categories to continuous numerical by replacing values\n",
    "# least likely to be approved gets 1\n",
    "# most likely to be approved gets highest value (=number of options)\n",
    "# remaining ones are ranked accordingly\n",
    "\n",
    "# look at distinct values\n",
    "print(artworks[\"district\"].value_counts())\n",
    "print(\"\\n\")\n",
    "\n",
    "# for column \"type\"\n",
    "artworks_processed[\"type\"] = artworks_processed[\"type\"].map({\n",
    "    \"painting\": 5,\n",
    "    \"graffiti\": 4,\n",
    "    \"poster\": 3,\n",
    "    \"stencil\": 2,\n",
    "    \"text\": 1\n",
    "})\n",
    "\n",
    "# implement for remaining columns here\n",
    "\n",
    "# have a look at current state of data frame\n",
    "print(artworks_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and preparing the data\n",
    "\"\"\"\n",
    "Things still to do:\n",
    "\n",
    "-fill NaN in column \"userRating\" with 0\n",
    "-replace all of the categories with numerical values. \n",
    "    least likely to be approved gets 1\n",
    "    most likely to be approved gets highest value (=number of options)\n",
    "    rank remaining categories accordingly\n",
    "-make sure all of the columns are numerical as opposed to character\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "# remember that 650/1000 are labeled yet. Either label remaining ones or shorten the set\n",
    "# training data  is for training the algorithm \n",
    "# test set is for evaluating the algorithm\n",
    "# both must be strictly separated\n",
    "\n",
    "# features are type, district, environment, countArtists, experience, replaced, content, user rating\n",
    "# label is \"approved\"\n",
    "# select features and label e.g. like this \n",
    "# features = data[[\"type\", \"district\", \"...\"]]\n",
    "# label = data[\"approved\"]\n",
    "# or as in the example: features is called X and label is called y\n",
    "# They did it like that:\n",
    "# X = fruits[[\"mass\", \"width\", \"height\"]]\n",
    "# y = fruits[\"fruit_label\"]\n",
    "# They then split the data like this: \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "# note that random state is for setting seed and this is necessary because they work for a large audience that wants to reproduce the result. \n",
    "# I may not need this parameter, depending on if I want to get a new result each time or not.\n",
    "# Alright, to reliably assess, you even NEED to have a look at multiple splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "# to see range of values, outliers and so on (or actually less in my example, because the values are categorical lol)\n",
    "# try to see if a potential algorithm is likely to be able to classify the data -> a well defined cluster should be visible\n",
    "\n",
    "# good plots to visualise the data: \n",
    "# 1) feature-pair plot\n",
    "# their code:\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap(\"gnuplot\")\n",
    "scatter = pd.scatter_matrix(X_train, c = y_train, marker = \"o\", s = 40, hist_kwds = {\"bins\":15}, figsize = (12, 12), cmap = cmap)\n",
    "# furthermore: \n",
    "# just look at for example how many of the artworks are paintings and the distribution over the districts.\n",
    "# the data is synthetic, so this is basically meaningless.\n",
    "# because of that, e.g., compare it to the probabilities that I set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHINE LEARNING ALGORITHM LEARNING, OPTIONS, DECISION MAKING AND BRAINSTORM\n",
    "# THIS BRANCH AND FILE IS FOR DATA PREPARATION, WRITE THE ACTUAL ML PART IN IT'S OWN BRANCH AND FILE\n",
    "# THIS CELL IS JUST TO TAKE NOTES AND SO ON \n",
    "\"\"\"\n",
    "ML algorithm options\n",
    "-k-nearest neighbors: instance or memory based learning\n",
    "Would likely work for my data set\n",
    "Likely pretty easy: k=1 (one nearest neighbor)\n",
    "It needs: a distance metric, k (how many nearest neighbors), weighting function on the neighbor points (not all neigh. have same influence), method for aggregating classes of neighbor points (how to combine influence and decide)\n",
    "Distance: scikit uses euclidian distance per default\n",
    "Neighbors: e.g. 5 (odd -> no tie -> no weighting necessary)\n",
    "Weighting: not necessary, when k/2=0.5\n",
    "Aggregation: Majority vote\n",
    "Use-case/code in the video: about knn\n",
    "-decision tree would also be very nice\n",
    "BUT scikit learn can only handle numeric features and beyond that, it will interpret them as continuous numeric variables.\n",
    "The problem I have here, namely that some of my features are discrete categorical strings, will thus not be solved by using decision trees in scikit learn or just substituting them by numbers, because they have no order\n",
    "-> use knn, it will be more practical, since we had several hours of teaching about that and only 19 min about decision trees.\n",
    "\n",
    "Assess the performance of the algorithm later on:\n",
    "e.g. compute accuracy of the classifier -> score method\n",
    "Also (if I will actually use knn,) try different values for k and then assess accuracy, because overfitting IS an issue!\n",
    "Also assess using different splits of the data set into training and test set. \n",
    "-> Cross validation -> There is a function for this (cross_val_score()) and I do not need to do this via hardcoding. \n",
    "Cross validation takes time, but my data set is pretty small, so just do it, since it has benefits. \n",
    "Code for assessing can be found in the second notebook of the ML part.\n",
    "A good test score (with good = close to 1) will be more important than a good train score for this.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

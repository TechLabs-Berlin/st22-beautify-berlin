{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "artworks = pd.read_table(\"beautified_boxes.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "prepare the data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "# remember that 650/1000 are labeled yet. Either label remaining ones or shorten the set\n",
    "# training data  is for training the algorithm \n",
    "# test set is for evaluating the algorithm\n",
    "# both must be strictly separated\n",
    "\n",
    "# features are type, district, environment, countArtists, experience, replaced, content, user rating\n",
    "# label is \"approved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "# to see range of values, outliers and so on (or actually less in my example, because the values are categorical lol)\n",
    "# try to see if a potential algorithm is likely to be able to classify the data -> a well defined cluster should be visible\n",
    "\n",
    "# good plots to visualise the data: \n",
    "# 1) feature-pair plot\n",
    "# their code:\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap(\"gnuplot\")\n",
    "scatter = pd.scatter_matrix(X_train, c = y_train, marker = \"o\", s = 40, hist_kwds = {\"bins\":15}, figsize = (12, 12), cmap = cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ML algorithm options\n",
    "-k-nearest neighbors: instance or memory based learning\n",
    "Would likely work for my data set\n",
    "Likely pretty easy: k=1 (one nearest neighbor)\n",
    "It needs: a distance metric, k (how many nearest neighbors), weighting function on the neighbor points (not all neigh. have same influence), method for aggregating classes of neighbor points (how to combine influence and decide)\n",
    "Distance: scikit uses euclidian distance per default\n",
    "Neighbors: e.g. 5 (odd -> no tie -> no weighting necessary)\n",
    "Weighting: not necessary, when k/2=0.5\n",
    "Aggregation: Majority vote\n",
    "Use-case/code in the video: about knn\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the workspace\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "artworks = pd.read_table(\"beautified_boxes.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning and preparing the data\n",
    "\"\"\"\n",
    "Things still to do:\n",
    "Basically, I made all of the decisions and took notes here or at least wrote down all of the feasible options. Implement all of this in the form of code now.\n",
    "label all of the remaining rows in the data set in the branch \"mock data\", then commit, push, merge into main and pull changes into this branch (\"data_preparation\"), because the data set is not up to date yet\n",
    "empty user ratings will be interpreted as nan by python -> handle this! I would say filling with average does not make sense, but a missing user rating definitely influenced my decision. Maybe fill with a new label, \n",
    "because I actually kinda handled it like that. If it had no label, chances were slimmer to get approval.\n",
    "Then have a look at the columns and so on. In this branch, the columns are a bit silly, but this may get resolved by pulling the real data set. Still, check it out when it comes to loading the data.\n",
    "Later on, when I use the data for the ML algorithm, I do not need all of the columns. For example, I do not actually need the ID, I think. I should think about dropping it here or I just keep it in the data set and \n",
    "later just select the needed columns.\n",
    "In case I will actually use knn (which currently really is the most likely option), then I cannot just use categorical data in form of strings.\n",
    "I then need to convert it to numbers. This, however is ONLY possible (possible meaning that the outcome will make any sense still), if there is some natural order in the data. \n",
    "In that case, I would, e.g., assign 1 to the lowest category of this order and e.g., 5 to the highest.\n",
    "This would work for e.g., type and number of artists, but not for the district. \n",
    "This also means that I cannot use all of my columns. Maybe I will find another classification option which is able to use categories or I will just select the useful ones.\n",
    "If I cannot find another one, I must cut down on my columns/features (, which won't be a huge problem, but which is unfortunate).\n",
    "Alternatively, I could also generate synthetic data with sklearn, which contains only numerical data, but the problem here is, that while this may work well for the ML algorithm, it would not be meaningful data...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "# remember that 650/1000 are labeled yet. Either label remaining ones or shorten the set\n",
    "# training data  is for training the algorithm \n",
    "# test set is for evaluating the algorithm\n",
    "# both must be strictly separated\n",
    "\n",
    "# features are type, district, environment, countArtists, experience, replaced, content, user rating\n",
    "# label is \"approved\"\n",
    "# select features and label e.g. like this \n",
    "# features = data[[\"type\", \"district\", \"...\"]]\n",
    "# label = data[\"approved\"]\n",
    "# or as in the example: features is called X and label is called y\n",
    "# They did it like that:\n",
    "# X = fruits[[\"mass\", \"width\", \"height\"]]\n",
    "# y = fruits[\"fruit_label\"]\n",
    "# They then split the data like this: \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) \n",
    "# note that random state is for setting seed and this is necessary because they work for a large audience that wants to reproduce the result. \n",
    "# I may not need this parameter, depending on if I want to get a new result each time or not.\n",
    "# Alright, to reliably assess, you even NEED to have a look at multiple splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisations\n",
    "# to see range of values, outliers and so on (or actually less in my example, because the values are categorical lol)\n",
    "# try to see if a potential algorithm is likely to be able to classify the data -> a well defined cluster should be visible\n",
    "\n",
    "# good plots to visualise the data: \n",
    "# 1) feature-pair plot\n",
    "# their code:\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap(\"gnuplot\")\n",
    "scatter = pd.scatter_matrix(X_train, c = y_train, marker = \"o\", s = 40, hist_kwds = {\"bins\":15}, figsize = (12, 12), cmap = cmap)\n",
    "# furthermore: \n",
    "# just look at for example how many of the artworks are paintings and the distribution over the districts.\n",
    "# the data is synthetic, so this is basically meaningless.\n",
    "# because of that, e.g., compare it to the probabilities that I set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACHINE LEARNING ALGORITHM LEARNING, OPTIONS, DECISION MAKING AND BRAINSTORM\n",
    "# THIS BRANCH AND FILE IS FOR DATA PREPARATION, WRITE THE ACTUAL ML PART IN IT'S OWN BRANCH AND FILE\n",
    "# THIS CELL IS JUST TO TAKE NOTES AND SO ON \n",
    "\"\"\"\n",
    "ML algorithm options\n",
    "-k-nearest neighbors: instance or memory based learning\n",
    "Would likely work for my data set\n",
    "Likely pretty easy: k=1 (one nearest neighbor)\n",
    "It needs: a distance metric, k (how many nearest neighbors), weighting function on the neighbor points (not all neigh. have same influence), method for aggregating classes of neighbor points (how to combine influence and decide)\n",
    "Distance: scikit uses euclidian distance per default\n",
    "Neighbors: e.g. 5 (odd -> no tie -> no weighting necessary)\n",
    "Weighting: not necessary, when k/2=0.5\n",
    "Aggregation: Majority vote\n",
    "Use-case/code in the video: about knn\n",
    "-decision tree would also be very nice\n",
    "BUT scikit learn can only handle numeric features and beyond that, it will interpret them as continuous numeric variables.\n",
    "The problem I have here, namely that some of my features are discrete categorical strings, will thus not be solved by using decision trees in scikit learn or just substituting them by numbers, because they have no order\n",
    "-> use knn, it will be more practical, since we had several hours of teaching about that and only 19 min about decision trees.\n",
    "\n",
    "Assess the performance of the algorithm later on:\n",
    "e.g. compute accuracy of the classifier -> score method\n",
    "Also (if I will actually use knn,) try different values for k and then assess accuracy, because overfitting IS an issue!\n",
    "Also assess using different splits of the data set into training and test set. \n",
    "-> Cross validation -> There is a function for this (cross_val_score()) and I do not need to do this via hardcoding. \n",
    "Cross validation takes time, but my data set is pretty small, so just do it, since it has benefits. \n",
    "Code for assessing can be found in the second notebook of the ML part.\n",
    "A good test score (with good = close to 1) will be more important than a good train score for this.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edf5cd947724a80ed2c702be8f4b172c0ff1a221cdb2f83bc9d53948019d2307"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
